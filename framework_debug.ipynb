{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b16170-9ac5-485a-995b-ebb8bbf0b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from belle2_enhanced_framework import create_belle2_framework\n",
    "# framework = create_belle2_framework(particle_type='vpho', memory_budget_gb=32.0,energy_condition='5S_scan')\n",
    "# processes = framework.load_particle_data(\n",
    "#     \"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\",\n",
    "#     particle='vpho'  # Automatically uses VPHO_KEYS columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86aca2af-5d06-4662-9bbf-26a4ffbb7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "                        Belle II Layer 2\n",
      "                   Compute-First Data Structures\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "    Components:\n",
      "    ├── UnifiedLazyDataFrame\n",
      "    │   └── Manifests compute graphs as DataFrames\n",
      "    ├── OptimizedUltraLazyDict\n",
      "    │   └── Process-aware container with groups\n",
      "    ├── MaterializationController\n",
      "    │   └── Intelligent format selection\n",
      "    ├── GraphOptimizationEngine\n",
      "    │   └── Automatic compute graph optimization\n",
      "    └── MemoryAwareExecutor\n",
      "        └── Adaptive execution with spilling\n",
      "    \n",
      "    Key Features:\n",
      "    • Zero-copy operations through compute graphs\n",
      "    • Automatic billion-row handling\n",
      "    • C++ acceleration for critical operations\n",
      "    • Physics-specific optimizations\n",
      "    • Full transformation tracking\n",
      "    \n",
      "    Usage:\n",
      "    >>> framework = Belle2Layer2Framework(memory_budget_gb=16.0)\n",
      "    >>> data = framework.load_processes(\"/data/belle2/vpho\")\n",
      "    >>> result = data.mumu.query('pRecoil > 2').hist('M_bc')\n",
      "    \n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# !pip3 install polars\n",
    "# !pip install dill\n",
    "from belle2_enhanced_framework import create_belle2_framework, ParticleDataLoaderV3\n",
    "framework = create_belle2_framework(energy_condition='4S_offres')\n",
    "loader = ParticleDataLoaderV3(particle_type='vpho', config=framework.config)\n",
    "processes = loader.load_flat_structure(\n",
    "    base_dir='/pnfs/desy.de/belle/local/user/sraiz/photon_efficiency/gammaEffKLM_Prompt_combinedFilesMerged',\n",
    "    data_type='selected'  # or 'matched'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9adef5bf-eb70-42c5-a220-8bf51285304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "                        Belle II Layer 2\n",
      "                   Compute-First Data Structures\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "    Components:\n",
      "    ├── UnifiedLazyDataFrame\n",
      "    │   └── Manifests compute graphs as DataFrames\n",
      "    ├── OptimizedUltraLazyDict\n",
      "    │   └── Process-aware container with groups\n",
      "    ├── MaterializationController\n",
      "    │   └── Intelligent format selection\n",
      "    ├── GraphOptimizationEngine\n",
      "    │   └── Automatic compute graph optimization\n",
      "    └── MemoryAwareExecutor\n",
      "        └── Adaptive execution with spilling\n",
      "    \n",
      "    Key Features:\n",
      "    • Zero-copy operations through compute graphs\n",
      "    • Automatic billion-row handling\n",
      "    • C++ acceleration for critical operations\n",
      "    • Physics-specific optimizations\n",
      "    • Full transformation tracking\n",
      "    \n",
      "    Usage:\n",
      "    >>> framework = Belle2Layer2Framework(memory_budget_gb=16.0)\n",
      "    >>> data = framework.load_processes(\"/data/belle2/vpho\")\n",
      "    >>> result = data.mumu.query('pRecoil > 2').hist('M_bc')\n",
      "    \n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "✓ Generated mc16-mumu-prompt_selected.parquet: 1,000 events\n",
      "✓ Generated mc16-ee-prompt_selected.parquet: 500 events\n",
      "✓ Generated mc16-taupair-prompt_selected.parquet: 100 events\n",
      "✓ Generated mc16-uubar-prompt_selected.parquet: 200 events\n",
      "✓ Generated mc16-ddbar-prompt_selected.parquet: 200 events\n",
      "✓ Generated mc16-ssbar-prompt_selected.parquet: 200 events\n",
      "✓ Generated mc16-ccbar-prompt_selected.parquet: 200 events\n",
      "✓ Generated data-prompt_selected.parquet: 500 events\n",
      "✓ Generated mc16-mumu-offprompt_selected.parquet: 1,000 events\n",
      "✓ Generated mc16-ee-offprompt_selected.parquet: 500 events\n",
      "✓ Generated mc16-taupair-offprompt_selected.parquet: 100 events\n",
      "✓ Generated mc16-uubar-offprompt_selected.parquet: 200 events\n",
      "✓ Generated mc16-ddbar-offprompt_selected.parquet: 200 events\n",
      "✓ Generated mc16-ssbar-offprompt_selected.parquet: 200 events\n",
      "✓ Generated mc16-ccbar-offprompt_selected.parquet: 200 events\n",
      "✓ Generated data-offprompt_selected.parquet: 500 events\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-mumu-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ee-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-taupair-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-uubar-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ddbar-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ssbar-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ccbar-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/data-prompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-mumu-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ee-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-taupair-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-uubar-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ddbar-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ssbar-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/mc16-ccbar-offprompt_selected.parquet\n",
      "\n",
      "🔍 Validating dataset: synthetic_test_data/data-offprompt_selected.parquet\n",
      "🚀 Initializing enhanced C++ accelerator...\n",
      "✅ Loaded existing C++ accelerator\n",
      "✅ C++ histogram acceleration: ACTIVE\n",
      "📊 System analysis:\n",
      "   Available memory: 490.9 GB\n",
      "   Optimal chunk size: 1,000,000 elements\n",
      "📊 Process limits: soft=2060546, hard=2060546\n",
      "🔧 Max Python threads: 16\n",
      "✅ C++ histogram acceleration available\n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║          Belle II Layer 2 Framework                ║\n",
      "        ║                                                    ║\n",
      "        ║  Memory Budget:  16.0 GB                     ║\n",
      "        ║  C++ Acceleration:  Enabled                 ║\n",
      "        ║  Cache Directory: /afs/desy.de/user/k/kyldem/.belle2_cache║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║     Belle II Enhanced Production Framework v3      ║\n",
      "        ║                                                    ║\n",
      "        ║  ✓ Clean weight/data separation                   ║\n",
      "        ║  ✓ Unified histogram pipeline                     ║\n",
      "        ║  ✓ Consistent C++ acceleration                    ║\n",
      "        ║  ✓ Full backward compatibility                    ║\n",
      "        ║  ✓ Energy filtering & method injection            ║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "🔍 Loading selected data from flat structure in ./synthetic_test_data\n",
      "   📁 Found process: ccbar-offprompt (1 files)\n",
      "   📁 Found process: ccbar-prompt (1 files)\n",
      "   📁 Found process: data-offprompt (1 files)\n",
      "   📁 Found process: data-prompt (1 files)\n",
      "   📁 Found process: ddbar-offprompt (1 files)\n",
      "   📁 Found process: ddbar-prompt (1 files)\n",
      "   📁 Found process: ee-offprompt (1 files)\n",
      "   📁 Found process: ee-prompt (1 files)\n",
      "   📁 Found process: mumu-offprompt (1 files)\n",
      "   📁 Found process: mumu-prompt (1 files)\n",
      "   📁 Found process: ssbar-offprompt (1 files)\n",
      "   📁 Found process: ssbar-prompt (1 files)\n",
      "   📁 Found process: taupair-offprompt (1 files)\n",
      "   📁 Found process: taupair-prompt (1 files)\n",
      "   📁 Found process: uubar-offprompt (1 files)\n",
      "   📁 Found process: uubar-prompt (1 files)\n",
      "   📊 Found 16 processes\n",
      "\n",
      "   Loading mumu-offprompt...\n",
      "✅ C++ histogram acceleration: ACTIVE\n",
      "📊 System analysis:\n",
      "   Available memory: 490.9 GB\n",
      "   Optimal chunk size: 1,000,000 elements\n",
      "📊 Process limits: soft=2060546, hard=2060546\n",
      "🔧 Max Python threads: 16\n",
      "      ✅ mumu-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading ee-offprompt...\n",
      "      ✅ ee-offprompt: Loaded with weight=10.5153\n",
      "\n",
      "   Loading taupair-offprompt...\n",
      "      ✅ taupair-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading uubar-offprompt...\n",
      "      ✅ uubar-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading ddbar-offprompt...\n",
      "      ✅ ddbar-offprompt: Loaded with weight=0.2472\n",
      "\n",
      "   Loading ssbar-offprompt...\n",
      "      ✅ ssbar-offprompt: Loaded with weight=0.2472\n",
      "\n",
      "   Loading ccbar-offprompt...\n",
      "      ✅ ccbar-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading data-offprompt...\n",
      "      ✅ data-offprompt: Loaded with weight=1.0000\n",
      "✅ Successfully loaded 8 processes\n",
      "\n",
      "🎯 PROGRESSIVE ANALYSIS: pRecoil\n",
      "============================================================\n",
      "\n",
      "📊 STAGE: baseline\n",
      "------------------------------\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/desy.de/user/k/kyldem/belle2_framework_code/layer2_unified_lazy_dataframe.py:423: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  if hasattr(frame, 'schema'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Collected 1,000 rows in 0.01s (0.1M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 1,000 / 1,000 (100.0% efficiency)\n",
      "   Time: 0.01s (0.1M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ mumu-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 500 rows in 0.01s (0.0M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 500 / 1,000 (50.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ee-offprompt: Histogram computed (w=10.5153)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 100 rows in 0.01s (0.0M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 100 / 1,000 (10.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ taupair-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 200 rows in 0.01s (0.0M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 200 / 1,000 (20.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ uubar-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 200 rows in 0.01s (0.0M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 200 / 1,000 (20.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ddbar-offprompt: Histogram computed (w=0.2472)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 200 rows in 0.01s (0.0M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 200 / 1,000 (20.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ssbar-offprompt: Histogram computed (w=0.2472)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 200 rows in 0.01s (0.0M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 200 / 1,000 (20.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ccbar-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using FALLBACK_BASIC strategy\n",
      "🚀 Materializing compute graph with 1,000 estimated rows...\n",
      "✅ Collected 500 rows in 0.01s (0.1M rows/s)\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: FALLBACK_BASIC\n",
      "   Rows: 500 / 1,000 (50.0% efficiency)\n",
      "   Time: 0.01s (0.0M rows/s)\n",
      "   Memory Peak: 0.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ data-offprompt: Histogram computed \n",
      "\n",
      "📊 STAGE: candidates\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "SOURCE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     18\u001b[0m processes \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_flat_structure(\n\u001b[1;32m     19\u001b[0m     base_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./synthetic_test_data\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Step 4: Execute analysis pipeline\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mframework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_progressive_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpRecoil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcandidates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/belle2_framework_code/belle2_enhanced_framework.py:1843\u001b[0m, in \u001b[0;36mBelle2ProductionFrameworkV3.run_progressive_analysis\u001b[0;34m(self, processes, variable, bins, range, cuts, stages, output_dir)\u001b[0m\n\u001b[1;32m   1836\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m ProgressiveAnalysisV3(\n\u001b[1;32m   1837\u001b[0m     processes, \n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_pipeline\n\u001b[1;32m   1840\u001b[0m )\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[0;32m-> 1843\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;66;03m# Add performance data\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistogram_pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_pipeline\u001b[38;5;241m.\u001b[39mget_performance_report(),\n\u001b[1;32m   1855\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframework\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofile_performance()\n\u001b[1;32m   1856\u001b[0m }\n",
      "File \u001b[0;32m~/belle2_framework_code/belle2_enhanced_framework.py:1265\u001b[0m, in \u001b[0;36mProgressiveAnalysisV3.run_analysis\u001b[0;34m(self, variable, bins, range, cuts, stages, output_dir)\u001b[0m\n\u001b[1;32m   1249\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m'\u001b[39m: variable,\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatistics\u001b[39m\u001b[38;5;124m'\u001b[39m: {}\n\u001b[1;32m   1262\u001b[0m }\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m stages:\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;66;03m# Generate efficiency plot if applicable\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficiency\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stages:\n",
      "File \u001b[0;32m~/belle2_framework_code/belle2_enhanced_framework.py:1308\u001b[0m, in \u001b[0;36mProgressiveAnalysisV3._execute_stage\u001b[0;34m(self, stage, variable, bins, range, cuts, output_path, results)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;66;03m# Get stage data\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m stage_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_stage_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;66;03m# Validate columns\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_stage_columns(stage_data, variable)\n",
      "File \u001b[0;32m~/belle2_framework_code/belle2_enhanced_framework.py:1350\u001b[0m, in \u001b[0;36mProgressiveAnalysisV3._get_stage_data\u001b[0;34m(self, stage, cuts)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, weighted_df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 1350\u001b[0m         result[name] \u001b[38;5;241m=\u001b[39m \u001b[43mweighted_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moneCandOnly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuts\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cuts:\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;66;03m# Apply cuts sequentially\u001b[39;00m\n",
      "File \u001b[0;32m~/belle2_framework_code/belle2_enhanced_framework.py:148\u001b[0m, in \u001b[0;36mWeightedDataFrame.oneCandOnly\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moneCandOnly\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeightedDataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Select one candidate with weight preservation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moneCandOnly\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WeightedDataFrame(new_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_histogram_engine)\n",
      "File \u001b[0;32m~/belle2_framework_code/layer2_unified_lazy_dataframe.py:1192\u001b[0m, in \u001b[0;36mUnifiedLazyDataFrame.oneCandOnly\u001b[0;34m(self, group_cols, sort_col, ascending)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moneCandOnly fallback due to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39msample(fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m df\n\u001b[1;32m   1189\u001b[0m one_cand_node \u001b[38;5;241m=\u001b[39m GraphNode(\n\u001b[1;32m   1190\u001b[0m     op_type\u001b[38;5;241m=\u001b[39mComputeOpType\u001b[38;5;241m.\u001b[39mAGGREGATE,\n\u001b[1;32m   1191\u001b[0m     operation\u001b[38;5;241m=\u001b[39mone_cand_operation,\n\u001b[0;32m-> 1192\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_root_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[1;32m   1193\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_candidate_only\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_cols\u001b[39m\u001b[38;5;124m'\u001b[39m: group_cols}\n\u001b[1;32m   1194\u001b[0m )\n\u001b[1;32m   1196\u001b[0m estimated_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimated_rows \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m   1197\u001b[0m new_compute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_compute_capability(one_cand_node, estimated_groups)\n",
      "File \u001b[0;32m~/belle2_framework_code/layer2_unified_lazy_dataframe.py:898\u001b[0m, in \u001b[0;36mUnifiedLazyDataFrame._get_root_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fallback_materialize\n\u001b[1;32m    897\u001b[0m \u001b[38;5;66;03m# Pass lazy_frames to FallbackNode for data access\u001b[39;00m\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFallbackNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlazy_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_lazy_frames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/belle2_framework_code/layer2_unified_lazy_dataframe.py:862\u001b[0m, in \u001b[0;36mUnifiedLazyDataFrame._get_root_node.<locals>.FallbackNode.__init__\u001b[0;34m(self, lazy_frames)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lazy_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_type \u001b[38;5;241m=\u001b[39m \u001b[43mComputeOpType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOURCE\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfallback\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e)}\n",
      "File \u001b[0;32m/cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/enum.py:786\u001b[0m, in \u001b[0;36mEnumType.__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_map_[name]\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: SOURCE"
     ]
    }
   ],
   "source": [
    "from belle2_enhanced_framework import create_belle2_framework,ParticleDataLoaderV3\n",
    "from streamlined_belle2_generator import QuickBelle2Generator\n",
    "from belle2_data_validation import DataValidationFramework\n",
    "\n",
    "# Step 1: Generate validated test data\n",
    "generator = QuickBelle2Generator('./synthetic_test_data')\n",
    "files = generator.generate_standard_files(scale=0.001)  # Start small\n",
    "\n",
    "# Step 2: Validate structural integrity\n",
    "validator = DataValidationFramework()\n",
    "for filepath in files.values():\n",
    "    report = validator.validate_dataset(filepath)\n",
    "    assert report['overall_score'] > 90, f\"Validation failed for {filepath}\"\n",
    "\n",
    "# Step 3: Load through standard framework\n",
    "framework = create_belle2_framework(energy_condition='4S_offres')\n",
    "loader = ParticleDataLoaderV3(particle_type='vpho', config=framework.config)\n",
    "processes = loader.load_flat_structure(\n",
    "    base_dir='./synthetic_test_data',\n",
    "    data_type='selected'\n",
    ")\n",
    "\n",
    "# Step 4: Execute analysis pipeline\n",
    "results = framework.run_progressive_analysis(\n",
    "    processes,\n",
    "    variable='pRecoil',\n",
    "    bins=100,\n",
    "    range=(0.1, 6.0),\n",
    "    stages=['baseline', 'candidates']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af1b321-4f3a-413b-b048-267b599463a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/site-packages/PyFastBDT-5.2-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: psutil in /cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/site-packages (5.9.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "                        Belle II Layer 2\n",
      "                   Compute-First Data Structures\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "    Components:\n",
      "    ├── UnifiedLazyDataFrame\n",
      "    │   └── Manifests compute graphs as DataFrames\n",
      "    ├── OptimizedUltraLazyDict\n",
      "    │   └── Process-aware container with groups\n",
      "    ├── MaterializationController\n",
      "    │   └── Intelligent format selection\n",
      "    ├── GraphOptimizationEngine\n",
      "    │   └── Automatic compute graph optimization\n",
      "    └── MemoryAwareExecutor\n",
      "        └── Adaptive execution with spilling\n",
      "    \n",
      "    Key Features:\n",
      "    • Zero-copy operations through compute graphs\n",
      "    • Automatic billion-row handling\n",
      "    • C++ acceleration for critical operations\n",
      "    • Physics-specific optimizations\n",
      "    • Full transformation tracking\n",
      "    \n",
      "    Usage:\n",
      "    >>> framework = Belle2Layer2Framework(memory_budget_gb=16.0)\n",
      "    >>> data = framework.load_processes(\"/data/belle2/vpho\")\n",
      "    >>> result = data.mumu.query('pRecoil > 2').hist('M_bc')\n",
      "    \n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "\n",
      "📊 Analyzing pRecoil...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'framework' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_name, bins, range_tuple \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 Analyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mframework\u001b[49m\u001b[38;5;241m.\u001b[39mrun_progressive_analysis(\n\u001b[1;32m     21\u001b[0m         processes,\n\u001b[1;32m     22\u001b[0m         variable\u001b[38;5;241m=\u001b[39mvar_name,\n\u001b[1;32m     23\u001b[0m         bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mrange_tuple,\n\u001b[1;32m     25\u001b[0m         cuts\u001b[38;5;241m=\u001b[39muser_cuts,\n\u001b[1;32m     26\u001b[0m         stages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandidates\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuts\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Standard progression\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     all_results[var_name] \u001b[38;5;241m=\u001b[39m results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'framework' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n",
    "from importlib import reload\n",
    "import belle2_enhanced_framework\n",
    "reload(belle2_enhanced_framework)\n",
    "from belle2_enhanced_framework import create_belle2_framework, OptimizedUltraLazyDict\n",
    "# Run analysis for each variable\n",
    "# Define variables with their binning\n",
    "variables = [\n",
    "    ('pRecoil', 100, (0.1, 6)),\n",
    "\n",
    "    # ('mu1P', 60, (0, 3)),\n",
    "    # ('mu2P', 60, (0, 3)),\n",
    "]\n",
    "# Define physics cuts\n",
    "full_cut = 'mu1nCDCHits>4&mu2nCDCHits>4&0.8>mu1clusterEoP&0.8>mu2clusterEoP&2.6179938779914944>pRecoilTheta>0.29670597283903605&11>totalMuonMomentum&absdPhi>1.5707963267948966&2.03>mu1Theta>0.61&2.03>mu2Theta>0.61&(absdPhiMu1>0.4014257279586958|absdThetaMu1>0.4014257279586958)&(absdPhiMu2>0.4014257279586958|absdThetaMu2>0.4014257279586958)&0.35>mu1clusterE&0.35>mu2clusterE&3>abs(m2Recoil)&min_deltaMuPRecoil>-0.01'\n",
    "user_cuts = full_cut.split('&') if full_cut else []\n",
    "all_results = {}\n",
    "for var_name, bins, range_tuple in variables:\n",
    "    print(f\"\\n📊 Analyzing {var_name}...\")\n",
    "    results = framework.run_progressive_analysis(\n",
    "        processes,\n",
    "        variable=var_name,\n",
    "        bins=bins,\n",
    "        range=range_tuple,\n",
    "        cuts=user_cuts,\n",
    "        stages=['baseline', 'candidates', 'cuts'],  # Standard progression\n",
    "    )\n",
    "    all_results[var_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa48c77-bdaa-45e7-8f87-d75eba33b178",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424d9c4-d042-4d3f-88cb-098ded1b8cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Belle2 (light-2505-deimos)",
   "language": "python",
   "name": "belle2_light-2505-deimos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

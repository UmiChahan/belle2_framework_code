{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b16170-9ac5-485a-995b-ebb8bbf0b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from belle2_enhanced_framework import create_belle2_framework\n",
    "# framework = create_belle2_framework(particle_type='vpho', memory_budget_gb=32.0,energy_condition='5S_scan')\n",
    "# processes = framework.load_particle_data(\n",
    "#     \"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\",\n",
    "#     particle='vpho'  # Automatically uses VPHO_KEYS columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86aca2af-5d06-4662-9bbf-26a4ffbb7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C++ histogram acceleration: ACTIVE\n",
      "📊 System analysis:\n",
      "   Available memory: 495.8 GB\n",
      "   Optimal chunk size: 1,000,000 elements\n",
      "📊 Process limits: soft=2060546, hard=2060546\n",
      "🔧 Max Python threads: 16\n",
      "✅ C++ histogram acceleration available\n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║          Belle II Layer 2 Framework                ║\n",
      "        ║                                                    ║\n",
      "        ║  Memory Budget:  16.0 GB                     ║\n",
      "        ║  C++ Acceleration:  Enabled                 ║\n",
      "        ║  Cache Directory: /afs/desy.de/user/k/kyldem/.belle2_cache║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║     Belle II Enhanced Production Framework v3      ║\n",
      "        ║                                                    ║\n",
      "        ║  ✓ Clean weight/data separation                   ║\n",
      "        ║  ✓ Unified histogram pipeline                     ║\n",
      "        ║  ✓ Consistent C++ acceleration                    ║\n",
      "        ║  ✓ Full backward compatibility                    ║\n",
      "        ║  ✓ Energy filtering & method injection            ║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "🔍 Loading selected data from flat structure in /pnfs/desy.de/belle/local/user/sraiz/photon_efficiency/gammaEffKLM_Prompt_combinedFilesMerged\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 121] Remote I/O error: '/pnfs/desy.de/belle/local/user/sraiz/photon_efficiency/gammaEffKLM_Prompt_combinedFilesMerged'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m framework \u001b[38;5;241m=\u001b[39m create_belle2_framework(energy_condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4S_offres\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m loader \u001b[38;5;241m=\u001b[39m ParticleDataLoaderV3(particle_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvpho\u001b[39m\u001b[38;5;124m'\u001b[39m, config\u001b[38;5;241m=\u001b[39mframework\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m----> 6\u001b[0m processes \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_flat_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/pnfs/desy.de/belle/local/user/sraiz/photon_efficiency/gammaEffKLM_Prompt_combinedFilesMerged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselected\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'matched'\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/belle2_framework_code/belle2_enhanced_framework.py:1062\u001b[0m, in \u001b[0;36mParticleDataLoaderV3.load_flat_structure\u001b[0;34m(self, base_dir, data_type, pattern, columns, sample_fraction)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data from flat structure in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m base_path \u001b[38;5;241m=\u001b[39m Path(base_dir)\n\u001b[0;32m-> 1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase directory not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# Discover files and group by process\u001b[39;00m\n",
      "File \u001b[0;32m/cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/pathlib.py:1235\u001b[0m, in \u001b[0;36mPath.exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;124;03mWhether this path exists.\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[0;32m/cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m    os.stat() does.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;28mself\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 121] Remote I/O error: '/pnfs/desy.de/belle/local/user/sraiz/photon_efficiency/gammaEffKLM_Prompt_combinedFilesMerged'"
     ]
    }
   ],
   "source": [
    "# !pip3 install polars\n",
    "# !pip install dill\n",
    "from belle2_enhanced_framework import create_belle2_framework, ParticleDataLoaderV3\n",
    "framework = create_belle2_framework(energy_condition='4S_offres')\n",
    "loader = ParticleDataLoaderV3(particle_type='vpho', config=framework.config)\n",
    "processes = loader.load_flat_structure(\n",
    "    base_dir='/pnfs/desy.de/belle/local/user/sraiz/photon_efficiency/gammaEffKLM_Prompt_combinedFilesMerged',\n",
    "    data_type='selected'  # or 'matched'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adef5bf-eb70-42c5-a220-8bf51285304c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "                        Belle II Layer 2\n",
      "                   Compute-First Data Structures\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "    Components:\n",
      "    ├── UnifiedLazyDataFrame\n",
      "    │   └── Manifests compute graphs as DataFrames\n",
      "    ├── OptimizedUltraLazyDict\n",
      "    │   └── Process-aware container with groups\n",
      "    ├── MaterializationController\n",
      "    │   └── Intelligent format selection\n",
      "    ├── GraphOptimizationEngine\n",
      "    │   └── Automatic compute graph optimization\n",
      "    └── MemoryAwareExecutor\n",
      "        └── Adaptive execution with spilling\n",
      "    \n",
      "    Key Features:\n",
      "    • Zero-copy operations through compute graphs\n",
      "    • Automatic billion-row handling\n",
      "    • C++ acceleration for critical operations\n",
      "    • Physics-specific optimizations\n",
      "    • Full transformation tracking\n",
      "    \n",
      "    Usage:\n",
      "    >>> framework = Belle2Layer2Framework(memory_budget_gb=16.0)\n",
      "    >>> data = framework.load_processes(\"/data/belle2/vpho\")\n",
      "    >>> result = data.mumu.query('pRecoil > 2').hist('M_bc')\n",
      "    \n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "🚀 Initializing enhanced C++ accelerator...\n",
      "⚠️ Some C++ functions not available: /afs/desy.de/user/k/kyldem/.belle2_cache/histogram_accelerator.so: undefined symbol: compute_weighted_histogram_avx2\n",
      "✅ Loaded existing C++ accelerator\n",
      "✅ C++ histogram acceleration: ACTIVE\n",
      "📊 System analysis:\n",
      "   Available memory: 493.4 GB\n",
      "   Optimal chunk size: 1,000,000 elements\n",
      "📊 Process limits: soft=2060546, hard=2060546\n",
      "🔧 Max Python threads: 16\n",
      "✅ C++ histogram acceleration available\n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║          Belle II Layer 2 Framework                ║\n",
      "        ║                                                    ║\n",
      "        ║  Memory Budget:  16.0 GB                     ║\n",
      "        ║  C++ Acceleration:  Enabled                 ║\n",
      "        ║  Cache Directory: /afs/desy.de/user/k/kyldem/.belle2_cache║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║     Belle II Enhanced Production Framework v3      ║\n",
      "        ║                                                    ║\n",
      "        ║  ✓ Clean weight/data separation                   ║\n",
      "        ║  ✓ Unified histogram pipeline                     ║\n",
      "        ║  ✓ Consistent C++ acceleration                    ║\n",
      "        ║  ✓ Full backward compatibility                    ║\n",
      "        ║  ✓ Energy filtering & method injection            ║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "🔍 Loading selected data from flat structure in ./synthetic_test_data\n",
      "   📁 Found process: ccbar-offprompt (1 files)\n",
      "   📁 Found process: ccbar-prompt (1 files)\n",
      "   📁 Found process: data-offprompt (1 files)\n",
      "   📁 Found process: data-prompt (1 files)\n",
      "   📁 Found process: ddbar-offprompt (1 files)\n",
      "   📁 Found process: ddbar-prompt (1 files)\n",
      "   📁 Found process: ee-offprompt (1 files)\n",
      "   📁 Found process: ee-prompt (1 files)\n",
      "   📁 Found process: mumu-offprompt (1 files)\n",
      "   📁 Found process: mumu-prompt (1 files)\n",
      "   📁 Found process: ssbar-offprompt (1 files)\n",
      "   📁 Found process: ssbar-prompt (1 files)\n",
      "   📁 Found process: taupair-offprompt (1 files)\n",
      "   📁 Found process: taupair-prompt (1 files)\n",
      "   📁 Found process: uubar-offprompt (1 files)\n",
      "   📁 Found process: uubar-prompt (1 files)\n",
      "   📊 Found 16 processes\n",
      "\n",
      "   Loading mumu-offprompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/desy.de/user/k/kyldem/belle2_framework_code/layer2_unified_lazy_dataframe.py:424: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  if hasattr(frame, 'schema'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C++ histogram acceleration: ACTIVE\n",
      "📊 System analysis:\n",
      "   Available memory: 492.4 GB\n",
      "   Optimal chunk size: 1,000,000 elements\n",
      "📊 Process limits: soft=2060546, hard=2060546\n",
      "🔧 Max Python threads: 16\n",
      "      ✅ mumu-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading ee-offprompt...\n",
      "      ✅ ee-offprompt: Loaded with weight=10.5153\n",
      "\n",
      "   Loading taupair-offprompt...\n",
      "      ✅ taupair-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading uubar-offprompt...\n",
      "      ✅ uubar-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading ddbar-offprompt...\n",
      "      ✅ ddbar-offprompt: Loaded with weight=0.2472\n",
      "\n",
      "   Loading ssbar-offprompt...\n",
      "      ✅ ssbar-offprompt: Loaded with weight=0.2472\n",
      "\n",
      "   Loading ccbar-offprompt...\n",
      "      ✅ ccbar-offprompt: Loaded with weight=0.2629\n",
      "\n",
      "   Loading data-offprompt...\n",
      "      ✅ data-offprompt: Loaded with weight=1.0000\n",
      "✅ Successfully loaded 8 processes\n",
      "\n",
      "🎯 PROGRESSIVE ANALYSIS: pRecoil\n",
      "============================================================\n",
      "\n",
      "📊 STAGE: baseline\n",
      "------------------------------\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 9,000,000 / 10,000,000 (90.0% efficiency)\n",
      "   Time: 0.44s (20.3M rows/s)\n",
      "   Memory Peak: 395.9MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ mumu-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 4,500,000 / 5,000,000 (90.0% efficiency)\n",
      "   Time: 0.20s (22.7M rows/s)\n",
      "   Memory Peak: 53.7MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ee-offprompt: Histogram computed (w=10.5153)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 900,000 / 1,000,000 (90.0% efficiency)\n",
      "   Time: 0.07s (13.4M rows/s)\n",
      "   Memory Peak: 27.5MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ taupair-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 1,800,000 / 2,000,000 (90.0% efficiency)\n",
      "   Time: 0.10s (17.8M rows/s)\n",
      "   Memory Peak: 28.7MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ uubar-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 1,800,000 / 2,000,000 (90.0% efficiency)\n",
      "   Time: 0.09s (19.0M rows/s)\n",
      "   Memory Peak: 19.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ddbar-offprompt: Histogram computed (w=0.2472)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 1,800,000 / 2,000,000 (90.0% efficiency)\n",
      "   Time: 0.10s (18.1M rows/s)\n",
      "   Memory Peak: 14.8MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ssbar-offprompt: Histogram computed (w=0.2472)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 1,800,000 / 2,000,000 (90.0% efficiency)\n",
      "   Time: 0.10s (17.5M rows/s)\n",
      "   Memory Peak: 15.3MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ ccbar-offprompt: Histogram computed (w=0.2629)\n",
      "📊 Histogram computation for 'pRecoil' using CPP_ACCELERATED strategy\n",
      "   Using C++ accelerated histogram\n",
      "⚠️ C++ histogram failed: type object 'cpp_histogram_integrator' has no attribute 'lib', falling back to Polars\n",
      "   Using Polars histogram implementation\n",
      "\n",
      "📊 Histogram Performance Summary:\n",
      "   Strategy: CPP_ACCELERATED\n",
      "   Rows: 4,500,000 / 5,000,000 (90.0% efficiency)\n",
      "   Time: 0.21s (21.3M rows/s)\n",
      "   Memory Peak: 31.0MB\n",
      "   Chunks: 1 (size: 0)\n",
      "   ✓ data-offprompt: Histogram computed \n",
      "\n",
      "📊 STAGE: candidates\n",
      "------------------------------\n",
      "   🔬 oneCandOnly: 9,000,000 → ~900,000 rows (expected)\n",
      "   📊 mumu: 9,000,000 → 900,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 4,500,000 → ~450,000 rows (expected)\n",
      "   📊 ee: 4,500,000 → 450,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 900,000 → ~90,000 rows (expected)\n",
      "   📊 taupair: 900,000 → 90,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 1,800,000 → ~180,000 rows (expected)\n",
      "   📊 uubar: 1,800,000 → 180,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 1,800,000 → ~180,000 rows (expected)\n",
      "   📊 ddbar: 1,800,000 → 180,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 1,800,000 → ~180,000 rows (expected)\n",
      "   📊 ssbar: 1,800,000 → 180,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 1,800,000 → ~180,000 rows (expected)\n",
      "   📊 ccbar: 1,800,000 → 180,000 rows (oneCandOnly)\n",
      "   🔬 oneCandOnly: 4,500,000 → ~450,000 rows (expected)\n",
      "   📊 data-offprompt: 4,500,000 → 450,000 rows (oneCandOnly)\n",
      "📊 Histogram computation for 'pRecoil' using LAZY_CHUNKED strategy\n"
     ]
    }
   ],
   "source": [
    "from belle2_enhanced_framework import create_belle2_framework,ParticleDataLoaderV3\n",
    "from streamlined_belle2_generator import QuickBelle2Generator\n",
    "from belle2_data_validation import DataValidationFramework\n",
    "\n",
    "# Step 1: Generate validated test data\n",
    "# generator = QuickBelle2Generator('./synthetic_test_data')\n",
    "# files = generator.generate_standard_files(scale=10)  # Start small\n",
    "\n",
    "# Step 2: Validate structural integrity\n",
    "# validator = DataValidationFramework()\n",
    "# for filepath in files.values():\n",
    "#     report = validator.validate_dataset(filepath)\n",
    "#     assert report['overall_score'] > 90, f\"Validation failed for {filepath}\"\n",
    "\n",
    "# Step 3: Load through standard framework\n",
    "framework = create_belle2_framework(energy_condition='4S_offres')\n",
    "loader = ParticleDataLoaderV3(particle_type='vpho', config=framework.config)\n",
    "processes = loader.load_flat_structure(\n",
    "    base_dir='./synthetic_test_data',\n",
    "    data_type='selected'\n",
    ")\n",
    "\n",
    "# Step 4: Execute analysis pipeline\n",
    "results = framework.run_progressive_analysis(\n",
    "    processes,\n",
    "    variable='pRecoil',\n",
    "    bins=100,\n",
    "    range=(0.1, 6.0),\n",
    "    stages=['baseline', 'candidates']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af1b321-4f3a-413b-b048-267b599463a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/site-packages/PyFastBDT-5.2-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: psutil in /cvmfs/belle.cern.ch/el9/externals/v02-03-00/Linux_x86_64/common/lib/python3.11/site-packages (5.9.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "                        Belle II Layer 2\n",
      "                   Compute-First Data Structures\n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "    Components:\n",
      "    ├── UnifiedLazyDataFrame\n",
      "    │   └── Manifests compute graphs as DataFrames\n",
      "    ├── OptimizedUltraLazyDict\n",
      "    │   └── Process-aware container with groups\n",
      "    ├── MaterializationController\n",
      "    │   └── Intelligent format selection\n",
      "    ├── GraphOptimizationEngine\n",
      "    │   └── Automatic compute graph optimization\n",
      "    └── MemoryAwareExecutor\n",
      "        └── Adaptive execution with spilling\n",
      "    \n",
      "    Key Features:\n",
      "    • Zero-copy operations through compute graphs\n",
      "    • Automatic billion-row handling\n",
      "    • C++ acceleration for critical operations\n",
      "    • Physics-specific optimizations\n",
      "    • Full transformation tracking\n",
      "    \n",
      "    Usage:\n",
      "    >>> framework = Belle2Layer2Framework(memory_budget_gb=16.0)\n",
      "    >>> data = framework.load_processes(\"/data/belle2/vpho\")\n",
      "    >>> result = data.mumu.query('pRecoil > 2').hist('M_bc')\n",
      "    \n",
      "    ═══════════════════════════════════════════════════════════════\n",
      "    \n",
      "\n",
      "📊 Analyzing pRecoil...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'framework' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_name, bins, range_tuple \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 Analyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mframework\u001b[49m\u001b[38;5;241m.\u001b[39mrun_progressive_analysis(\n\u001b[1;32m     21\u001b[0m         processes,\n\u001b[1;32m     22\u001b[0m         variable\u001b[38;5;241m=\u001b[39mvar_name,\n\u001b[1;32m     23\u001b[0m         bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mrange_tuple,\n\u001b[1;32m     25\u001b[0m         cuts\u001b[38;5;241m=\u001b[39muser_cuts,\n\u001b[1;32m     26\u001b[0m         stages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandidates\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuts\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Standard progression\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     all_results[var_name] \u001b[38;5;241m=\u001b[39m results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'framework' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n",
    "from importlib import reload\n",
    "import belle2_enhanced_framework\n",
    "reload(belle2_enhanced_framework)\n",
    "from belle2_enhanced_framework import create_belle2_framework, OptimizedUltraLazyDict\n",
    "# Run analysis for each variable\n",
    "# Define variables with their binning\n",
    "variables = [\n",
    "    ('pRecoil', 100, (0.1, 6)),\n",
    "\n",
    "    # ('mu1P', 60, (0, 3)),\n",
    "    # ('mu2P', 60, (0, 3)),\n",
    "]\n",
    "# Define physics cuts\n",
    "full_cut = 'mu1nCDCHits>4&mu2nCDCHits>4&0.8>mu1clusterEoP&0.8>mu2clusterEoP&2.6179938779914944>pRecoilTheta>0.29670597283903605&11>totalMuonMomentum&absdPhi>1.5707963267948966&2.03>mu1Theta>0.61&2.03>mu2Theta>0.61&(absdPhiMu1>0.4014257279586958|absdThetaMu1>0.4014257279586958)&(absdPhiMu2>0.4014257279586958|absdThetaMu2>0.4014257279586958)&0.35>mu1clusterE&0.35>mu2clusterE&3>abs(m2Recoil)&min_deltaMuPRecoil>-0.01'\n",
    "user_cuts = full_cut.split('&') if full_cut else []\n",
    "all_results = {}\n",
    "for var_name, bins, range_tuple in variables:\n",
    "    print(f\"\\n📊 Analyzing {var_name}...\")\n",
    "    results = framework.run_progressive_analysis(\n",
    "        processes,\n",
    "        variable=var_name,\n",
    "        bins=bins,\n",
    "        range=range_tuple,\n",
    "        cuts=user_cuts,\n",
    "        stages=['baseline', 'candidates', 'cuts'],  # Standard progression\n",
    "    )\n",
    "    all_results[var_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa48c77-bdaa-45e7-8f87-d75eba33b178",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424d9c4-d042-4d3f-88cb-098ded1b8cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Belle2 (light-2505-deimos)",
   "language": "python",
   "name": "belle2_light-2505-deimos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

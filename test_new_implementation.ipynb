{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfef0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import chdir\n",
    "# chdir('/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project')\n",
    "# from data_MC_test import run_belle2_mc_data_comparison, HistogramConfig, PlotStyle\n",
    "# variables = [\n",
    "    \n",
    "#     HistogramConfig(\n",
    "#         variable=\"pRecoil\",\n",
    "#         bins=50,\n",
    "#         range=(0, 4),\n",
    "#         xlabel=r\"$p_{\\mathrm{recoil}}$ [GeV/$c$]\",\n",
    "#         log_y=True\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Define user cuts\n",
    "# full_cut='mu1nCDCHits>4&mu2nCDCHits>4&0.8>mu1clusterEoP&0.8>mu2clusterEoP&2.6179938779914944>pRecoilTheta>0.29670597283903605&11>totalMuonMomentum&absdPhi>1.5707963267948966&2.03>mu1Theta>0.61&2.03>mu2Theta>0.61&(absdPhiMu1>0.4014257279586958|absdThetaMu1>0.4014257279586958)&(absdPhiMu2>0.4014257279586958|absdThetaMu2>0.4014257279586958)&0.35>mu1clusterE&0.35>mu2clusterE&3>abs(m2Recoil)&min_deltaMuPRecoil>-0.01'\n",
    "# user_cuts =full_cut.split('&') if full_cut else []\n",
    "    \n",
    "\n",
    "\n",
    "# # Run analysis\n",
    "# results = run_belle2_mc_data_comparison(\n",
    "#     base_dir=\"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\",\n",
    "#     variables=variables,\n",
    "#     user_cuts=user_cuts,\n",
    "#     memory_budget_gb=32.0,\n",
    "#     output_dir=\".\",\n",
    "#     style=PlotStyle.BELLE2_OFFICIAL\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "import matplotlib.pyplot as plt\n",
    "chdir('/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project')\n",
    "from MC_data_ratio_try import run_belle2_analysis\n",
    "variables = [\n",
    "    ('pRecoil', 100, (0.1, 6)),\n",
    "    ('mu1P', 60, (0, 3)),\n",
    "    ('mu2P', 60, (0, 3)),\n",
    "]\n",
    "\n",
    "# Define physics cuts\n",
    "full_cut='mu1nCDCHits>4&mu2nCDCHits>4&0.8>mu1clusterEoP&0.8>mu2clusterEoP&2.6179938779914944>pRecoilTheta>0.29670597283903605&11>totalMuonMomentum&absdPhi>1.5707963267948966&2.03>mu1Theta>0.61&2.03>mu2Theta>0.61&(absdPhiMu1>0.4014257279586958|absdThetaMu1>0.4014257279586958)&(absdPhiMu2>0.4014257279586958|absdThetaMu2>0.4014257279586958)&0.35>mu1clusterE&0.35>mu2clusterE&3>abs(m2Recoil)&min_deltaMuPRecoil>-0.01'\n",
    "user_cuts =full_cut.split('&') if full_cut else []\n",
    "# Run analysis\n",
    "run_belle2_analysis(\n",
    "    base_dir=\"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\",\n",
    "    energy_condition='5S_scan',  # or '4S_on', '4S_offres', 'all'\n",
    "    variables=variables,\n",
    "    user_cuts=user_cuts,\n",
    "    file_type='vpho',\n",
    "    output_dir='.'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22950c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Method 2: Using fluent interface for more control\n",
    "# chain = AnalysisChain(framework)\n",
    "\n",
    "# # Load data and inspect\n",
    "# data = (chain\n",
    "#         .load(\"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\", \n",
    "#               particle='vpho')\n",
    "#         .get_current_data())\n",
    "\n",
    "# print(f\"Available processes: {list(data.keys())}\")\n",
    "# print(f\"Available groups: {data.list_groups()}\")\n",
    "\n",
    "# # Apply cuts progressively and compute histograms\n",
    "# results = chain\n",
    "\n",
    "# # Add cuts one by one (or all at once)\n",
    "# for cut in user_cuts:\n",
    "#     results = results.cut(cut)\n",
    "\n",
    "# # Compute histograms for each variable\n",
    "# for var_name, bins, range_tuple in variables:\n",
    "#     results = results.hist(var_name, bins=bins, range=range_tuple)\n",
    "\n",
    "# # Get all results\n",
    "# final_results = results.get()\n",
    "\n",
    "# # Method 3: Quick interactive exploration\n",
    "# # You can also explore data interactively before full analysis\n",
    "# print(\"\\n🔍 Interactive exploration:\")\n",
    "\n",
    "# # Check what columns are available\n",
    "# first_process = next(iter(processes.values()))\n",
    "# print(f\"Available columns: {first_process.columns[:20]}...\")  # First 20 columns\n",
    "\n",
    "# # Quick histogram of one variable\n",
    "# quick_hist = processes.hist('pRecoil', bins=50, range=(0.1, 6))\n",
    "# print(f\"Quick histogram computed for {len(quick_hist)} processes\")\n",
    "\n",
    "# # Apply cuts and check statistics\n",
    "# filtered = processes.oneCandOnly()\n",
    "# for cut in user_cuts[:3]:  # Apply first 3 cuts as example\n",
    "#     filtered = filtered.query(cut)\n",
    "    \n",
    "# # Check how many events survive\n",
    "# survival_stats = {}\n",
    "# for name, df in filtered.items():\n",
    "#     try:\n",
    "#         # This is still lazy - no computation yet\n",
    "#         survival_stats[name] = df.shape[0]  # Estimated rows\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# print(f\"Estimated events after cuts: {sum(survival_stats.values()):,}\")\n",
    "\n",
    "# # Method 4: Energy condition filtering (if needed)\n",
    "# # Filter processes by energy condition\n",
    "# if energy_condition == '5S_scan':\n",
    "#     # Filter to only 5S processes\n",
    "#     processes_5S = OptimizedUltraLazyDict(memory_budget_gb=16.0)\n",
    "#     for name, df in processes.items():\n",
    "#         if '5S' in name or 'scan' in name:  # Adjust pattern as needed\n",
    "#             processes_5S[name] = df\n",
    "#     processes = processes_5S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44832f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C++ histogram acceleration: ACTIVE\n",
      "📊 System analysis:\n",
      "   Available memory: 299.7 GB\n",
      "   Optimal chunk size: 1,000,000 elements\n",
      "📊 Process limits: soft=1024, hard=1024\n",
      "🔧 Max Python threads: 16\n",
      "✅ C++ histogram acceleration available\n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║          Belle II Layer 2 Framework                ║\n",
      "        ║                                                    ║\n",
      "        ║  Memory Budget:  32.0 GB                     ║\n",
      "        ║  C++ Acceleration:  Enabled                 ║\n",
      "        ║  Cache Directory: /home/belle2/kyldem/.belle2_cache║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "\n",
      "        ╔════════════════════════════════════════════════════╗\n",
      "        ║     Belle II Enhanced Production Framework v3      ║\n",
      "        ║                                                    ║\n",
      "        ║  ✓ Clean weight/data separation                   ║\n",
      "        ║  ✓ Unified histogram pipeline                     ║\n",
      "        ║  ✓ Consistent C++ acceleration                    ║\n",
      "        ║  ✓ Full backward compatibility                    ║\n",
      "        ║  ✓ Energy filtering & method injection            ║\n",
      "        ╚════════════════════════════════════════════════════╝\n",
      "        \n",
      "Loading vpho data...\n",
      "🔍 Loading vpho data with weight calculation\n",
      "🔍 Loading vpho data from /gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\n",
      "   Using 46 default columns for vpho\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_ssbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_llXX_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_ccbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ee_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_data5S_p16_v2 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_taupair_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_uubar_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_ee_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ddbar_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_gg_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_charged_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_uubar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ee_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_uubar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_gg_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_gg_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_charged_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_llXX_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_ccbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_dataoff_p16_v2 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_ddbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_eemumu_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_eemumu_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_uubar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_data_prompt_v4 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_ee_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_mixed_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_mumu_p16_COMBINED (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_mixed_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_hhISR_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_taupair_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_gg_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ssbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_eemumu_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_eeee_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_taupair_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_hhISR_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_eeee_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_ssbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_dataoff_prompt_v4 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ssbar_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_mumu_p16_COMBINED (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_hhISR_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_ddbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ccbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ccbar_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_ddbar_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_taupair_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc_eeee_prompt_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_llXX_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_hhISR_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mcoff_eeee_p16_v1 (1 files)\n",
      "   📁 Found process: sample_name=P16M16rd_mc5S_eemumu_p16_v1 (1 files)\n",
      "   📊 Found 53 process directories\n",
      "\n",
      "   🔍 Applying 5S_scan energy filtering\n",
      "      Include patterns: ['5s', 'mc5s', 'data5s', 'scan5s', 'scan_5s', 'mc-5s', 'data-5s']\n",
      "      Exclude patterns: ['off', '4s', 'off_resonance', 'offres']\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_ssbar_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_llXX_prompt_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_ccbar_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ee_prompt_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_data5S_p16_v2\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_taupair_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_uubar_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_ee_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ddbar_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_gg_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_charged_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_uubar_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ee_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_uubar_p16_v1 (excluded)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_gg_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_gg_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_charged_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_llXX_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_ccbar_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_dataoff_p16_v2 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_ddbar_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_eemumu_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_eemumu_p16_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_uubar_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_data_prompt_v4 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_ee_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_mixed_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_mumu_p16_COMBINED (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_mixed_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_hhISR_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_taupair_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_gg_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ssbar_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_eemumu_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_eeee_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_taupair_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_hhISR_prompt_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_eeee_p16_v1\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_ssbar_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_dataoff_prompt_v4 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ssbar_prompt_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_mumu_p16_COMBINED\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_hhISR_p16_v1\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_ddbar_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ccbar_p16_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ccbar_prompt_v1 (not included)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_ddbar_p16_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_taupair_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mc_eeee_prompt_v1 (not included)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_llXX_p16_v1\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_hhISR_p16_v1 (excluded)\n",
      "      ✗ Filtered out: sample_name=P16M16rd_mcoff_eeee_p16_v1 (excluded)\n",
      "      ✓ Accepted: sample_name=P16M16rd_mc5S_eemumu_p16_v1\n",
      "\n",
      "   📊 Filtering result: 13/53 directories kept\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_ccbar_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_ccbar_p16_v1: Loaded with weight=0.2500\n",
      "\n",
      "   Loading sample_name=P16M16rd_data5S_p16_v2...\n",
      "      ✅ sample_name=P16M16rd_data5S_p16_v2: Loaded with weight=1.0000\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_gg_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_gg_p16_v1: Loaded with weight=0.5000\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_uubar_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_uubar_p16_v1: Loaded with weight=0.2500\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_ee_p16_v1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/layer2_unified_lazy_dataframe.py:851: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  if hasattr(frame, 'schema'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ✅ sample_name=P16M16rd_mc5S_ee_p16_v1: Loaded with weight=9.9999\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_eeee_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_eeee_p16_v1: Loaded with weight=9.9999\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_ssbar_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_ssbar_p16_v1: Loaded with weight=0.2500\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_mumu_p16_COMBINED...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ✅ sample_name=P16M16rd_mc5S_mumu_p16_COMBINED: Loaded with weight=0.2500\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_hhISR_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_hhISR_p16_v1: Loaded with weight=1.0000\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_ddbar_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_ddbar_p16_v1: Loaded with weight=0.2500\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_taupair_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_taupair_p16_v1: Loaded with weight=0.2500\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_llXX_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_llXX_p16_v1: Loaded with weight=1.0000\n",
      "\n",
      "   Loading sample_name=P16M16rd_mc5S_eemumu_p16_v1...\n",
      "      ✅ sample_name=P16M16rd_mc5S_eemumu_p16_v1: Loaded with weight=0.2500\n",
      "✅ Successfully loaded 13 processes\n",
      "✅ Loaded 13 processes with weights\n",
      "✅ Data loaded: 13 processes available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/layer2_unified_lazy_dataframe.py:1366: PerformanceWarning: determining the width of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().len()` to get the width without this warning.\n",
      "  hasattr(self._lazy_frames[0], 'width') and\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project')\n",
    "from belle2_enhanced_framework import create_belle2_framework, AnalysisChain\n",
    "\n",
    "\n",
    "# Method 1: Traditional approach with full analysis\n",
    "framework = create_belle2_framework(particle_type='vpho', memory_budget_gb=32.0,energy_condition='5S_scan')\n",
    "\n",
    "print(\"Loading vpho data...\")\n",
    "processes = framework.load_particle_data(\n",
    "    \"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\",\n",
    "    particle='vpho'  # Automatically uses VPHO_KEYS columns\n",
    ")\n",
    "print(f\"✅ Data loaded: {len(processes)} processes available\")\n",
    "\n",
    "\n",
    "results = processes['qqbar'].hist('pRecoil', bins=50,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd826b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BroadcastResult(operation='qqbar.hist', successful=0/4, errors=4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba8caf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Analyzing pRecoil...\n",
      "\n",
      "🎯 PROGRESSIVE ANALYSIS: pRecoil\n",
      "============================================================\n",
      "\n",
      "📊 STAGE: baseline\n",
      "------------------------------\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 887 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ccbar_p16_v1: Histogram computed (w=0.2500)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 4,656,626 counts\n",
      "   ✓ sample_name=P16M16rd_data5S_p16_v2: Histogram computed \n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 11,258 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_gg_p16_v1: Histogram computed (w=0.5000)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 425,554 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_uubar_p16_v1: Histogram computed (w=0.2500)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 107,191 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ee_p16_v1: Histogram computed (w=9.9999)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 387 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_eeee_p16_v1: Histogram computed (w=9.9999)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 25,393 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ssbar_p16_v1: Histogram computed (w=0.2500)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 30,517,370 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_mumu_p16_COMBINED: Histogram computed (w=0.2500)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 13,524 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_hhISR_p16_v1: Histogram computed (w=1.0000)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 117,461 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ddbar_p16_v1: Histogram computed (w=0.2500)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 143,118 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_taupair_p16_v1: Histogram computed (w=0.2500)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 3,935 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_llXX_p16_v1: Histogram computed (w=1.0000)\n",
      "🚀 Adaptive chunking: 1,000 rows for 1,000 dataset\n",
      "   ✅ Enhanced Polars: 0 events → 19,823 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_eemumu_p16_v1: Histogram computed (w=0.2500)\n",
      "\n",
      "📊 STAGE: candidates\n",
      "------------------------------\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ccbar_p16_v1: Histogram computed (w=0.2500)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_data5S_p16_v2: Histogram computed \n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_gg_p16_v1: Histogram computed (w=0.5000)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_uubar_p16_v1: Histogram computed (w=0.2500)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ee_p16_v1: Histogram computed (w=9.9999)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_eeee_p16_v1: Histogram computed (w=9.9999)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ssbar_p16_v1: Histogram computed (w=0.2500)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_mumu_p16_COMBINED: Histogram computed (w=0.2500)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_hhISR_p16_v1: Histogram computed (w=1.0000)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_ddbar_p16_v1: Histogram computed (w=0.2500)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_taupair_p16_v1: Histogram computed (w=0.2500)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_llXX_p16_v1: Histogram computed (w=1.0000)\n",
      "⚠️ Adaptive optimization failed: Invalid chunk size: 1000, using fallback\n",
      "🚀 Adaptive chunking: 200 rows for 200 dataset\n",
      "   ⚠️ Frame streaming error: The output schema of 'LazyFrame.map' is incorrect. Expected: Schema:\n",
      "name: __experiment__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __event__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "Got: Schema:\n",
      "name: __event__, field: Int64\n",
      "name: __run__, field: Int64\n",
      "name: __experiment__, field: Int64\n",
      "name: __production__, field: Int64\n",
      "name: __candidate__, field: Int64\n",
      "name: __ncandidates__, field: Int64\n",
      "name: pRecoilTheta, field: Float64\n",
      "name: pRecoilPhi, field: Float64\n",
      "name: eRecoil, field: Float64\n",
      "name: pRecoil, field: Float64\n",
      "name: mRecoil, field: Float64\n",
      "name: m2Recoil, field: Float64\n",
      "name: mu1clusterE, field: Float64\n",
      "name: mu2clusterE, field: Float64\n",
      "name: mu1clusterEoP, field: Float64\n",
      "name: mu2clusterEoP, field: Float64\n",
      "name: mu1clusterPhi, field: Float64\n",
      "name: mu2clusterPhi, field: Float64\n",
      "name: mu1clusterTheta, field: Float64\n",
      "name: mu2clusterTheta, field: Float64\n",
      "name: mu1nCDCHits, field: Float64\n",
      "name: mu2nCDCHits, field: Float64\n",
      "name: nGammaROE, field: Float64\n",
      "name: nTracksROE, field: Float64\n",
      "name: nPhotonCands, field: Int64\n",
      "name: nTracks, field: Int64\n",
      "name: sumE_offcone, field: Float64\n",
      "name: sumE_offcone_barrel, field: Float64\n",
      "name: totalMuonMomentum, field: Float64\n",
      "name: theta, field: Float64\n",
      "name: phi, field: Float64\n",
      "name: E, field: Float64\n",
      "name: beamE, field: Float64\n",
      "name: vpho_px, field: Float64\n",
      "name: vpho_py, field: Float64\n",
      "name: vpho_pz, field: Float64\n",
      "name: vpho_E, field: Float64\n",
      "name: psnm_ffo, field: Float64\n",
      "name: mu1Theta, field: Float64\n",
      "name: mu2Theta, field: Float64\n",
      "name: mu1Phi, field: Float64\n",
      "name: mu2Phi, field: Float64\n",
      "name: mu1E, field: Float64\n",
      "name: mu2E, field: Float64\n",
      "name: mu1P, field: Float64\n",
      "name: mu2P, field: Float64\n",
      "\n",
      "   ✅ Enhanced Polars: 0 events → 0 counts\n",
      "   ✓ sample_name=P16M16rd_mc5S_eemumu_p16_v1: Histogram computed (w=0.2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/belle2_enhanced_framework.py:1482: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax_main.set_yscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 STAGE: cuts\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'UnifiedLazyDataFrame' object has no attribute '_extract_columns_from_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_name, bins, range_tuple \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 Analyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mframework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_progressive_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcuts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_cuts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcandidates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Standard progression\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./analysis_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvar_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     all_results[var_name] \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/belle2_enhanced_framework.py:1674\u001b[0m, in \u001b[0;36mBelle2ProductionFrameworkV3.run_progressive_analysis\u001b[0;34m(self, processes, variable, bins, range, cuts, stages, output_dir)\u001b[0m\n\u001b[1;32m   1667\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m ProgressiveAnalysisV3(\n\u001b[1;32m   1668\u001b[0m     processes, \n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_pipeline\n\u001b[1;32m   1671\u001b[0m )\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[0;32m-> 1674\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;66;03m# Add performance data\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistogram_pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_pipeline\u001b[38;5;241m.\u001b[39mget_performance_report(),\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframework\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofile_performance()\n\u001b[1;32m   1687\u001b[0m }\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/belle2_enhanced_framework.py:1096\u001b[0m, in \u001b[0;36mProgressiveAnalysisV3.run_analysis\u001b[0;34m(self, variable, bins, range, cuts, stages, output_dir)\u001b[0m\n\u001b[1;32m   1080\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m'\u001b[39m: variable,\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatistics\u001b[39m\u001b[38;5;124m'\u001b[39m: {}\n\u001b[1;32m   1093\u001b[0m }\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m stages:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# Generate efficiency plot if applicable\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficiency\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stages:\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/belle2_enhanced_framework.py:1139\u001b[0m, in \u001b[0;36mProgressiveAnalysisV3._execute_stage\u001b[0;34m(self, stage, variable, bins, range, cuts, output_path, results)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# Get stage data\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m stage_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_stage_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# Validate columns\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_stage_columns(stage_data, variable)\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/belle2_enhanced_framework.py:1190\u001b[0m, in \u001b[0;36mProgressiveAnalysisV3._get_stage_data\u001b[0;34m(self, stage, cuts)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     df \u001b[38;5;241m=\u001b[39m weighted_df\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cut \u001b[38;5;129;01min\u001b[39;00m cuts:\n\u001b[0;32m-> 1190\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcut\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/belle2_enhanced_framework.py:142\u001b[0m, in \u001b[0;36mWeightedDataFrame.query\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, expr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeightedDataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Query that preserves weight information.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WeightedDataFrame(new_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_histogram_engine)\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/layer2_unified_lazy_dataframe.py:1492\u001b[0m, in \u001b[0;36mUnifiedLazyDataFrame.query\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, expr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnifiedLazyDataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Query with chain preservation.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1492\u001b[0m     required_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_columns_from_query\u001b[49m(expr)\n\u001b[1;32m   1493\u001b[0m     missing_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[1;32m   1496\u001b[0m         \u001b[38;5;66;03m# Attempt automatic resolution\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project/layer2_unified_lazy_dataframe.py:930\u001b[0m, in \u001b[0;36mUnifiedLazyDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;66;03m# Default behavior\u001b[39;00m\n\u001b[0;32m--> 930\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'UnifiedLazyDataFrame' object has no attribute '_extract_columns_from_query'"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import belle2_enhanced_framework\n",
    "reload(belle2_enhanced_framework)\n",
    "from belle2_enhanced_framework import create_belle2_framework, OptimizedUltraLazyDict\n",
    "# Run analysis for each variable\n",
    "# Define variables with their binning\n",
    "variables = [\n",
    "    ('pRecoil', 100, (0.1, 6)),\n",
    "    \n",
    "    ('mu1P', 60, (0, 3)),\n",
    "    ('mu2P', 60, (0, 3)),\n",
    "]\n",
    "\n",
    "# Define physics cuts\n",
    "full_cut = 'mu1nCDCHits>4&mu2nCDCHits>4&0.8>mu1clusterEoP&0.8>mu2clusterEoP&2.6179938779914944>pRecoilTheta>0.29670597283903605&11>totalMuonMomentum&absdPhi>1.5707963267948966&2.03>mu1Theta>0.61&2.03>mu2Theta>0.61&(absdPhiMu1>0.4014257279586958|absdThetaMu1>0.4014257279586958)&(absdPhiMu2>0.4014257279586958|absdThetaMu2>0.4014257279586958)&0.35>mu1clusterE&0.35>mu2clusterE&3>abs(m2Recoil)&min_deltaMuPRecoil>-0.01'\n",
    "user_cuts = full_cut.split('&') if full_cut else []\n",
    "\n",
    "all_results = {}\n",
    "for var_name, bins, range_tuple in variables:\n",
    "    print(f\"\\n📊 Analyzing {var_name}...\")\n",
    "    results = framework.run_progressive_analysis(\n",
    "        processes,\n",
    "        variable=var_name,\n",
    "        bins=bins,\n",
    "        range=range_tuple,\n",
    "        cuts=user_cuts,\n",
    "        stages=['baseline', 'candidates', 'cuts'],  # Standard progression\n",
    "        output_dir=f'./analysis_{var_name}'\n",
    "    )\n",
    "    all_results[var_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "# ============================================================================\n",
    "# IMMEDIATE EXECUTABLE DIAGNOSTIC SUITE\n",
    "# Run this directly on your processes object\n",
    "# ============================================================================\n",
    "\n",
    "def diagnose_silent_data_elimination(processes):\n",
    "    \"\"\"\n",
    "    Comprehensive diagnostic for candidate selection data loss.\n",
    "    \n",
    "    Execute immediately after candidate selection to identify why\n",
    "    histogram processing shows 0 rows despite successful execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n🔬 SILENT DATA ELIMINATION DIAGNOSTIC SUITE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Test baseline data availability\n",
    "    print(\"\\n📊 STAGE 1: Baseline Data Verification\")\n",
    "    first_name = next(iter(processes.keys()))\n",
    "    first_df = processes[first_name]\n",
    "    \n",
    "    print(f\"Testing with: {first_name}\")\n",
    "    print(f\"DataFrame type: {type(first_df).__name__}\")\n",
    "    \n",
    "    # Check data structure integrity\n",
    "    if hasattr(first_df, '_lazy_frames') and first_df._lazy_frames:\n",
    "        try:\n",
    "            frame = first_df._lazy_frames[0]\n",
    "            actual_count = frame.select(pl.len()).collect()[0, 0]\n",
    "            print(f\"✅ Underlying data: {actual_count:,} rows available\")\n",
    "            \n",
    "            # Check specific column\n",
    "            schema = frame.collect_schema()\n",
    "            has_mu2P = 'mu2P' in schema\n",
    "            print(f\"✅ Column 'mu2P' exists: {has_mu2P}\")\n",
    "            \n",
    "            if has_mu2P and actual_count > 0:\n",
    "                # Sample the data\n",
    "                sample = frame.select('mu2P').limit(5).collect()\n",
    "                non_null = sample['mu2P'].drop_nulls()\n",
    "                print(f\"✅ Sample data: {len(sample)} rows, {len(non_null)} non-null\")\n",
    "                if len(non_null) > 0:\n",
    "                    values = non_null.to_list()\n",
    "                    print(f\"   Sample values: {values}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Baseline data access failed: {e}\")\n",
    "    \n",
    "    # Test candidate selection impact\n",
    "    print(\"\\n📊 STAGE 2: Candidate Selection Impact Analysis\")\n",
    "    \n",
    "    try:\n",
    "        # Call oneCandOnly directly\n",
    "        print(\"Testing oneCandOnly() directly...\")\n",
    "        candidates_result = processes.oneCandOnly()\n",
    "        \n",
    "        print(f\"Candidates result type: {type(candidates_result).__name__}\")\n",
    "        print(f\"Valid results: {len(candidates_result._valid_results)}\")\n",
    "        \n",
    "        # Analyze each result\n",
    "        for name, result in list(candidates_result._valid_results.items())[:3]:\n",
    "            print(f\"\\n   Process: {name}\")\n",
    "            print(f\"   Result type: {type(result).__name__}\")\n",
    "            \n",
    "            # Check estimated vs actual rows\n",
    "            if hasattr(result, '_estimated_rows'):\n",
    "                estimated = result._estimated_rows\n",
    "                print(f\"   Estimated rows: {estimated}\")\n",
    "            \n",
    "            # Check lazy frames\n",
    "            if hasattr(result, '_lazy_frames') and result._lazy_frames:\n",
    "                try:\n",
    "                    frame = result._lazy_frames[0]\n",
    "                    actual_count = frame.select(pl.len()).collect()[0, 0]\n",
    "                    print(f\"   Actual LazyFrame rows: {actual_count} ⚠️\" if actual_count == 0 else f\"   Actual LazyFrame rows: {actual_count} ✅\")\n",
    "                    \n",
    "                    if actual_count == 0:\n",
    "                        # Diagnose why count is zero\n",
    "                        print(\"   🔍 ZERO ROWS DIAGNOSIS:\")\n",
    "                        \n",
    "                        # Check if LazyFrame has operations applied\n",
    "                        lazy_plan = str(frame)\n",
    "                        if 'GROUP BY' in lazy_plan:\n",
    "                            print(\"   - GROUP BY operation detected\")\n",
    "                        if 'FILTER' in lazy_plan:\n",
    "                            print(\"   - FILTER operation detected\")\n",
    "                        \n",
    "                        print(f\"   - LazyFrame plan: {lazy_plan[:200]}...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ LazyFrame analysis failed: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Candidate selection test failed: {e}\")\n",
    "    \n",
    "    # Test direct histogram on baseline\n",
    "    print(\"\\n📊 STAGE 3: Direct Histogram Test (Baseline)\")\n",
    "    \n",
    "    try:\n",
    "        first_df = processes[first_name]\n",
    "        if hasattr(first_df, '_lazy_frames') and first_df._lazy_frames:\n",
    "            # Direct histogram computation on original data\n",
    "            frame = first_df._lazy_frames[0]\n",
    "            \n",
    "            # Check if mu2P has data\n",
    "            if 'mu2P' in frame.collect_schema():\n",
    "                # Get basic statistics\n",
    "                stats = frame.select([\n",
    "                    pl.col('mu2P').count().alias('count'),\n",
    "                    pl.col('mu2P').min().alias('min'),\n",
    "                    pl.col('mu2P').max().alias('max'),\n",
    "                    pl.col('mu2P').mean().alias('mean')\n",
    "                ]).collect()\n",
    "                \n",
    "                print(f\"✅ Baseline mu2P statistics:\")\n",
    "                print(f\"   Count: {stats['count'][0]}\")\n",
    "                print(f\"   Range: [{stats['min'][0]:.3f}, {stats['max'][0]:.3f}]\")\n",
    "                print(f\"   Mean: {stats['mean'][0]:.3f}\")\n",
    "                \n",
    "                # This should work if data exists\n",
    "                if stats['count'][0] > 0:\n",
    "                    print(\"✅ Baseline data is viable for histogram\")\n",
    "                else:\n",
    "                    print(\"❌ Baseline data has no values for mu2P\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Direct histogram test failed: {e}\")\n",
    "    \n",
    "    return candidates_result if 'candidates_result' in locals() else None\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE DIAGNOSTIC\n",
    "# ============================================================================\n",
    "\n",
    "# Run this immediately\n",
    "diagnostic_result = diagnose_silent_data_elimination(processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39925ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TARGETED CANDIDATE SELECTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_candidate_selection_failure(processes):\n",
    "    \"\"\"\n",
    "    Focused analysis of why candidate selection eliminates all data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n🎯 TARGETED CANDIDATE SELECTION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    first_name = next(iter(processes.keys()))\n",
    "    first_df = processes[first_name]\n",
    "    \n",
    "    # Check grouping columns availability\n",
    "    print(\"📋 Grouping Columns Analysis:\")\n",
    "    \n",
    "    required_cols = ['__experiment__', '__run__', '__event__', '__production__']\n",
    "    \n",
    "    if hasattr(first_df, '_lazy_frames') and first_df._lazy_frames:\n",
    "        frame = first_df._lazy_frames[0]\n",
    "        schema = frame.collect_schema()\n",
    "        available_cols = list(schema.keys())\n",
    "        \n",
    "        print(f\"Total columns available: {len(available_cols)}\")\n",
    "        \n",
    "        # Check required columns\n",
    "        present = [col for col in required_cols if col in available_cols]\n",
    "        missing = [col for col in required_cols if col not in available_cols]\n",
    "        \n",
    "        print(f\"Required columns present: {present}\")\n",
    "        print(f\"Required columns missing: {missing}\")\n",
    "        \n",
    "        if len(present) >= 2:\n",
    "            print(\"✅ Sufficient columns for grouping\")\n",
    "            \n",
    "            # Test manual grouping\n",
    "            print(\"\\n🧪 Manual Grouping Test:\")\n",
    "            try:\n",
    "                # Use available columns for grouping\n",
    "                group_cols = present[:3]  # Use first 3 available\n",
    "                \n",
    "                print(f\"Testing with columns: {group_cols}\")\n",
    "                \n",
    "                # Manual group-by operation\n",
    "                grouped_count = frame.group_by(group_cols).agg(pl.count()).collect()\n",
    "                total_groups = len(grouped_count)\n",
    "                \n",
    "                print(f\"✅ Manual grouping successful: {total_groups} groups\")\n",
    "                \n",
    "                # Show sample groups\n",
    "                if total_groups > 0:\n",
    "                    print(\"Sample groups:\")\n",
    "                    for i in range(min(3, total_groups)):\n",
    "                        row = grouped_count[i]\n",
    "                        print(f\"   Group {i+1}: {dict(zip(group_cols + ['count'], row))}\")\n",
    "                \n",
    "                # Test first() operation\n",
    "                print(\"\\n🧪 First Selection Test:\")\n",
    "                first_selected = frame.group_by(group_cols).first().collect()\n",
    "                first_count = len(first_selected)\n",
    "                \n",
    "                print(f\"✅ First selection result: {first_count} rows\")\n",
    "                \n",
    "                if first_count == 0:\n",
    "                    print(\"❌ CRITICAL: First selection eliminates all data!\")\n",
    "                    \n",
    "                    # Investigate why\n",
    "                    print(\"🔍 Investigating first() elimination:\")\n",
    "                    \n",
    "                    # Check if any group actually has data\n",
    "                    sample_group = frame.group_by(group_cols).agg([\n",
    "                        pl.count().alias('group_size'),\n",
    "                        pl.col('mu2P').first().alias('first_mu2P')\n",
    "                    ]).collect()\n",
    "                    \n",
    "                    print(f\"Sample group analysis: {len(sample_group)} groups\")\n",
    "                    if len(sample_group) > 0:\n",
    "                        for i in range(min(3, len(sample_group))):\n",
    "                            row = sample_group[i]\n",
    "                            print(f\"   Group {i+1} size: {row['group_size']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Manual grouping failed: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        else:\n",
    "            print(\"❌ Insufficient columns for grouping\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Execute targeted analysis\n",
    "analyze_candidate_selection_failure(processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd65f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HISTOGRAM PIPELINE SPECIFIC DIAGNOSTIC\n",
    "# ============================================================================\n",
    "\n",
    "def diagnose_histogram_pipeline(processes):\n",
    "    \"\"\"\n",
    "    Diagnose why histogram shows 0 rows processed despite data availability.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n📊 HISTOGRAM PIPELINE DIAGNOSTIC\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get candidates result\n",
    "    candidates_result = processes.oneCandOnly()\n",
    "    first_name = next(iter(candidates_result._valid_results.keys()))\n",
    "    first_result = candidates_result._valid_results[first_name]\n",
    "    \n",
    "    print(f\"Testing histogram pipeline with: {first_name}\")\n",
    "    \n",
    "    # Step 1: Check result structure\n",
    "    print(\"\\n1️⃣ Result Structure Analysis:\")\n",
    "    print(f\"   Type: {type(first_result).__name__}\")\n",
    "    print(f\"   Has _lazy_frames: {hasattr(first_result, '_lazy_frames')}\")\n",
    "    print(f\"   Has _compute: {hasattr(first_result, '_compute')}\")\n",
    "    \n",
    "    # Step 2: Test data access methods\n",
    "    print(\"\\n2️⃣ Data Access Methods:\")\n",
    "    \n",
    "    if hasattr(first_result, '_lazy_frames') and first_result._lazy_frames:\n",
    "        try:\n",
    "            frame = first_result._lazy_frames[0]\n",
    "            count = frame.select(pl.count()).collect()[0, 0]\n",
    "            print(f\"   Direct LazyFrame access: {count} rows ✅\" if count > 0 else f\"   Direct LazyFrame access: {count} rows ❌\")\n",
    "            \n",
    "            if count > 0 and 'mu2P' in frame.collect_schema():\n",
    "                # Test column access\n",
    "                mu2P_stats = frame.select([\n",
    "                    pl.col('mu2P').count().alias('count'),\n",
    "                    pl.col('mu2P').is_null().sum().alias('nulls')\n",
    "                ]).collect()\n",
    "                \n",
    "                data_count = mu2P_stats['count'][0]\n",
    "                null_count = mu2P_stats['nulls'][0]\n",
    "                \n",
    "                print(f\"   mu2P column: {data_count} values, {null_count} nulls\")\n",
    "                \n",
    "                if data_count > null_count:\n",
    "                    print(\"   ✅ mu2P has actual data\")\n",
    "                    \n",
    "                    # Test manual histogram\n",
    "                    print(\"\\n3️⃣ Manual Histogram Test:\")\n",
    "                    try:\n",
    "                        # Simple histogram computation\n",
    "                        mu2P_values = frame.select('mu2P').collect()['mu2P'].drop_nulls()\n",
    "                        \n",
    "                        if len(mu2P_values) > 0:\n",
    "                            import numpy as np\n",
    "                            hist_counts, hist_edges = np.histogram(mu2P_values, bins=50)\n",
    "                            total_hist_counts = np.sum(hist_counts)\n",
    "                            \n",
    "                            print(f\"   ✅ Manual histogram: {total_hist_counts} total counts\")\n",
    "                            print(f\"   Value range: [{np.min(mu2P_values):.3f}, {np.max(mu2P_values):.3f}]\")\n",
    "                            \n",
    "                            if total_hist_counts > 0:\n",
    "                                print(\"   🎯 CONCLUSION: Data exists and can be histogrammed\")\n",
    "                                print(\"   🚨 ISSUE: Framework histogram pipeline is not accessing the data correctly\")\n",
    "                            \n",
    "                        else:\n",
    "                            print(\"   ❌ No non-null values found\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"   ❌ Manual histogram failed: {e}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ LazyFrame access failed: {e}\")\n",
    "    \n",
    "    # Step 3: Test compute capability\n",
    "    if hasattr(first_result, '_compute'):\n",
    "        print(\"\\n4️⃣ Compute Capability Test:\")\n",
    "        try:\n",
    "            materialized = first_result._compute.materialize()\n",
    "            print(f\"   Materialization type: {type(materialized)}\")\n",
    "            \n",
    "            if hasattr(materialized, '__len__'):\n",
    "                print(f\"   Materialized rows: {len(materialized)}\")\n",
    "            elif hasattr(materialized, 'height'):\n",
    "                print(f\"   Materialized rows: {materialized.height}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Compute materialization failed: {e}\")\n",
    "\n",
    "# Execute histogram pipeline diagnostic\n",
    "diagnose_histogram_pipeline(processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PRECISION HISTOGRAM PIPELINE REPAIR\n",
    "# ============================================================================\n",
    "\n",
    "def fix_histogram_data_access(processes):\n",
    "    \"\"\"\n",
    "    Surgical fix for histogram pipeline data access failure.\n",
    "    \n",
    "    Root Cause: Histogram method bypasses candidate selection results\n",
    "    Solution: Force histogram to use materialized compute capability\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n🔧 IMPLEMENTING HISTOGRAM PIPELINE REPAIR\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    def fixed_streaming_histogram(self, column: str, bins: int = 50,\n",
    "                                range=None, density: bool = False, \n",
    "                                weights: str = None):\n",
    "        \"\"\"\n",
    "        ENHANCED: Histogram computation that properly accesses transformed data.\n",
    "        \"\"\"\n",
    "        print(f\"📊 Enhanced histogram computation for '{column}'...\")\n",
    "        \n",
    "        # CRITICAL FIX: Use compute capability instead of raw lazy_frames\n",
    "        try:\n",
    "            # Step 1: Materialize the current state (includes all transformations)\n",
    "            materialized_data = self._compute.materialize()\n",
    "            \n",
    "            print(f\"   Materialized data: {len(materialized_data)} rows\")\n",
    "            \n",
    "            if len(materialized_data) == 0:\n",
    "                print(\"   ⚠️ No data after materialization\")\n",
    "                return np.zeros(bins), np.linspace(0, 1, bins + 1)\n",
    "            \n",
    "            # Step 2: Extract column data\n",
    "            if column not in materialized_data.columns:\n",
    "                print(f\"   ❌ Column '{column}' not found in materialized data\")\n",
    "                available_cols = list(materialized_data.columns)\n",
    "                print(f\"   Available columns: {available_cols[:10]}\")\n",
    "                return np.zeros(bins), np.linspace(0, 1, bins + 1)\n",
    "            \n",
    "            # Step 3: Get column values\n",
    "            column_values = materialized_data[column].drop_nulls()\n",
    "            \n",
    "            if len(column_values) == 0:\n",
    "                print(f\"   ⚠️ No non-null values in column '{column}'\")\n",
    "                return np.zeros(bins), np.linspace(0, 1, bins + 1)\n",
    "            \n",
    "            print(f\"   Processing {len(column_values)} values\")\n",
    "            \n",
    "            # Step 4: Compute histogram\n",
    "            import numpy as np\n",
    "            \n",
    "            # Convert to numpy for histogram computation\n",
    "            if hasattr(column_values, 'to_numpy'):\n",
    "                np_values = column_values.to_numpy()\n",
    "            else:\n",
    "                np_values = np.array(column_values.to_list())\n",
    "            \n",
    "            # Range determination\n",
    "            if range is None:\n",
    "                range = (float(np.min(np_values)), float(np.max(np_values)))\n",
    "                print(f\"   Auto-range: [{range[0]:.3f}, {range[1]:.3f}]\")\n",
    "            \n",
    "            # Compute histogram\n",
    "            counts, edges = np.histogram(np_values, bins=bins, range=range, density=density)\n",
    "            total_counts = np.sum(counts)\n",
    "            \n",
    "            print(f\"   ✅ Histogram computed: {total_counts} total counts\")\n",
    "            \n",
    "            return counts, edges\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Enhanced histogram failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Fallback to original method\n",
    "            return self._original_streaming_histogram(column, bins, range, density, weights)\n",
    "    \n",
    "    # Apply fix to all UnifiedLazyDataFrame instances\n",
    "    fixed_count = 0\n",
    "    \n",
    "    for name, df in processes.items():\n",
    "        if hasattr(df, '__class__') and 'UnifiedLazyDataFrame' in str(type(df)):\n",
    "            # Store original method\n",
    "            if not hasattr(df.__class__, '_original_streaming_histogram'):\n",
    "                df.__class__._original_streaming_histogram = df.__class__._streaming_histogram\n",
    "            \n",
    "            # Replace with fixed version\n",
    "            df.__class__._streaming_histogram = fixed_streaming_histogram\n",
    "            fixed_count += 1\n",
    "    \n",
    "    print(f\"✅ Histogram pipeline repaired for {fixed_count} processes\")\n",
    "    \n",
    "    return fixed_count\n",
    "\n",
    "# Execute the fix\n",
    "fix_count = fix_histogram_data_access(processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab707185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VALIDATION: Test Fixed Histogram Pipeline\n",
    "# ============================================================================\n",
    "\n",
    "def test_fixed_histogram_pipeline(processes):\n",
    "    \"\"\"\n",
    "    Validate that histogram pipeline now accesses candidate-selected data correctly.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n🧪 TESTING FIXED HISTOGRAM PIPELINE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get candidate selection result\n",
    "    candidates_result = processes.oneCandOnly()\n",
    "    \n",
    "    # Test histogram on first process\n",
    "    first_name = next(iter(candidates_result._valid_results.keys()))\n",
    "    first_result = candidates_result._valid_results[first_name]\n",
    "    \n",
    "    print(f\"Testing with: {first_name}\")\n",
    "    \n",
    "    # Test histogram computation\n",
    "    try:\n",
    "        counts, edges = first_result.hist('mu2P', bins=10)\n",
    "        total_counts = np.sum(counts)\n",
    "        \n",
    "        print(f\"✅ Fixed histogram result:\")\n",
    "        print(f\"   Total counts: {total_counts}\")\n",
    "        print(f\"   Bins: {len(counts)}\")\n",
    "        print(f\"   Range: [{edges[0]:.3f}, {edges[-1]:.3f}]\")\n",
    "        \n",
    "        if total_counts > 0:\n",
    "            print(\"🎯 SUCCESS: Histogram pipeline now accessing data correctly!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ Still showing zero counts\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fixed histogram test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Execute validation test\n",
    "test_success = test_fixed_histogram_pipeline(processes)\n",
    "\n",
    "if test_success:\n",
    "    print(\"\\n🚀 READY FOR ANALYSIS: Histogram pipeline restored\")\n",
    "else:\n",
    "    print(\"\\n⚠️ REQUIRES FURTHER INVESTIGATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e33d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/gpfs/group/belle2/users2022/kyldem/photoneff_updated/belle2_framework_project')\n",
    "# from belle2_enhanced_framework import create_belle2_framework, AnalysisChain\n",
    "# framework= create_belle2_framework(particle_type='vpho', memory_budget_gb=32.0, energy_condition='5S_scan')\n",
    "# processes = framework.load_particle_data(\n",
    "#     \"/gpfs/group/belle2/users2022/kyldem/photoneff_updated/parquet_storage/try5\",\n",
    "#     particle='vpho'  # Automatically uses VPHO_KEYS columns\n",
    "# )\n",
    "# processes['sample_name=P16M16rd_mc5S_gg_p16_v1'].columnsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166edffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer2_optimized_ultra_lazy_dict import OptimizedUltraLazyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7337226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this diagnostic right after data loading\n",
    "print(\"\\n🔍 COLUMN VISIBILITY DIAGNOSTIC\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "first_process_name = next(iter(processes.keys()))\n",
    "first_df = processes[first_process_name]\n",
    "\n",
    "print(f\"Process: {first_process_name}\")\n",
    "print(f\"Type: {type(first_df)}\")\n",
    "\n",
    "# Check schema vs columns\n",
    "if hasattr(first_df, '_schema'):\n",
    "    print(f\"Internal schema columns: {len(first_df._schema)}\")\n",
    "    print(f\"Schema keys: {list(first_df._schema.keys())[:10]}...\")\n",
    "\n",
    "if hasattr(first_df, 'required_columns'):\n",
    "    print(f\"Required columns constraint: {first_df.required_columns}\")\n",
    "\n",
    "print(f\"Visible columns: {len(first_df.columns)}\")\n",
    "print(f\"Visible columns: {first_df.columns}\")\n",
    "\n",
    "# Check if all columns exist in underlying data\n",
    "if hasattr(first_df, '_lazy_frames') and first_df._lazy_frames:\n",
    "    actual_schema = first_df._lazy_frames[0].collect_schema()\n",
    "    print(f\"Underlying Polars schema: {len(actual_schema)} columns\")\n",
    "    print(f\"First 10 underlying columns: {list(actual_schema.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "processes['qqbar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e075285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
